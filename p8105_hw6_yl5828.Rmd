---
title: "p8105_hw6_yl5828"
author: "Leah Li"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
editor_options: 
  chunk_output_type: console
---


## Problem 0

```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(patchwork)
library(rvest)
library(broom)
library(janitor)
library(modelr)


knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

```{r read in data, message=FALSE}
url <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data <- read_csv(url)
```


```{r data cleaning}
homicide_df <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>%
  mutate(resolved = as.numeric(disposition == "Closed by arrest")) %>%
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(victim_age = as.numeric(victim_age)) %>%
  filter(!is.na(victim_age)) %>%
  mutate(
    victim_sex = factor(victim_sex),
    victim_race = factor(victim_race)
  )
```



```{r logistic regression for Baltimore}
baltimore_df <- homicide_df %>%
  filter(city_state == "Baltimore, MD")

baltimore_glm <- glm(
  resolved ~ victim_age + victim_sex + victim_race,
  data = baltimore_df,
  family = binomial()
)

# Tidy the results
baltimore_results <- baltimore_glm %>%
  tidy() %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  filter(term == "victim_sexMale") %>%
  select(term, OR, CI_lower, CI_upper)
```

Baltimore, MD Results:  

For Baltimore, the adjusted odds ratio for solving homicides comparing male victims to female victims is
`r round(baltimore_results$OR, 3)` with 95% CI: (**`r round(baltimore_results$CI_lower, 3)`**, **`r round(baltimore_results$CI_upper, 3)`**).



```{r Analysis for all cities}
city_results <- homicide_df %>%
  nest(data = -city_state) %>%
  mutate(
    model = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
    tidied = map(model, tidy)) %>%
  unnest(tidied) %>%
  filter(term == "victim_sexMale") %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(city_state, OR, CI_lower, CI_upper) %>%
  arrange(OR)

city_results
```


```{r Create plot}
plot <- city_results %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), width = 0.3) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red", alpha = 0.7) +
  coord_flip() +
  labs(
    title = "Adjusted Odds Ratios for Solving Homicides: Male vs Female Victims",
    subtitle = "Adjusted for victim age and race across 47 U.S. cities",
    x = "City",
    y = "Odds Ratio (95% CI)") +
  theme_minimal()

plot
```


In the plot, most cities are clustered close to 1 and most 95% CIs cross the vertical line at 1, suggesting little evidence of large, consistent differences in clearance rates by victim sex within most cities. A few cities have ORs noticeably above 1, hinting that male-victim homicides might be more likely to be solved there, but their CIs are wide, so those estimates are fairly imprecise. Overall, there isn’t a strong pattern by city.



## Problem 2

```{r load packages}
library(p8105.datasets)
data("weather_df")
```


```{r calculation}
set.seed(1)

n_bootstrap <- 5000

boot_results <- 
  tibble(rep = 1:n_bootstrap) %>%
  mutate(
    sample = map(rep, ~ sample_n(weather_df, size = nrow(weather_df), replace = TRUE)),
    model = map(sample, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glance_output = map(model, glance),
    tidy_output = map(model, tidy),
    r_squared = map_dbl(glance_output, "r.squared"),
    beta1 = map_dbl(tidy_output, ~ .x$estimate[.x$term == "tmin"]),
    beta2 = map_dbl(tidy_output, ~ .x$estimate[.x$term == "prcp"]),
    beta_ratio = beta1 / beta2
  ) %>%
  select(rep, r_squared, beta_ratio)

# Calculate 95% confidence intervals
ci_r_squared <- quantile(boot_results$r_squared, c(0.025, 0.975))
ci_beta_ratio <- quantile(boot_results$beta_ratio, c(0.025, 0.975))

ci_r_squared
ci_beta_ratio
```


```{r distribution plots}
# Create plot for R-squared distribution
plot_r_squared <- boot_results %>%
  ggplot(aes(x = r_squared)) +
  geom_density(fill = "purple", alpha=0.5) +
  labs(
    title = "Bootstrap Distribution of R²",
    x = "R²",
    y = "Count"
  ) +
  theme_minimal()

# Create plot for beta ratio distribution
plot_beta_ratio <- boot_results %>%
  ggplot(aes(x = beta_ratio)) +
  geom_density(bins = 40, fill = "blue", alpha=0.5)  +
  labs(
    title = "Bootstrap Distribution of β1 / β2",
    x = "β1 / β2 (tmin coefficient / prcp coefficient)",
    y = "Count"
  ) +
  theme_minimal()

plot_r_squared
plot_beta_ratio
```

From the plots, we could observe that the bootstrap distribution of R² is approximately normal with a slight left skew, centered around 0.94, which indicates the model consistently explains a high proportion of variance in the data. In contrast, the distribution of the ratio β1 / β2 is heavily left-skewed with a significant tail extending toward more negative values; this asymmetry suggests instability in the estimate, likely caused by the denominator which is β2 the precipitation coefficient, being very close to zero in certain bootstrap samples, inflating the ratio.



## Problem 3

```{r import dataset}
birthweight_data = read_csv("data/birthweight.csv") |> 
  clean_names()
```


```{r birthweight data cleaning}
birthweight_df <- birthweight_data %>%
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("male", "female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("absent", "present"))
  )
```


```{r Proposed model and plot residual}
proposed_model <- lm(bwt ~ blength + bhead + babysex + gaweeks + 
                       ppbmi + wtgain + smoken + mrace + fincome, 
                     data = birthweight_df)

residual_plot <- birthweight_df %>%
  add_predictions(proposed_model, var = "fitted") %>%
  add_residuals(proposed_model, var = "residual") %>%
  ggplot(aes(x = fitted, y = residual)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
  labs(
    title = "Residuals vs Fitted Values - Proposed Model",
    x = "Fitted Values (grams)",
    y = "Residuals (grams)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))

residual_plot
```


```{r Cross-validation}
set.seed(123)

cv_df <- crossv_mc(birthweight_df, n = 100)

cv_results <- cv_df %>%
  mutate(
    model_main = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_interactions = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x)),
    model_proposed = map(train, ~lm(bwt ~ blength + bhead + babysex + gaweeks + 
                                      ppbmi + wtgain + smoken + mrace + fincome, 
                                    data = .x))
  ) %>%
  mutate(
    rmse_main = map2_dbl(model_main, test, ~rmse(.x, .y)),
    rmse_interactions = map2_dbl(model_interactions, test, ~rmse(.x, .y)),
    rmse_proposed = map2_dbl(model_proposed, test, ~rmse(.x, .y))
  )


rmse_summary <- cv_results %>%
  select(rmse_main, rmse_interactions, rmse_proposed) %>%
  pivot_longer(everything(), names_to = "model", values_to = "rmse") %>%
  mutate(model = case_when(
    model == "rmse_main" ~ "Main Effects",
    model == "rmse_interactions" ~ "Interactions",
    model == "rmse_proposed" ~ "Proposed Model"
  )) %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse = sd(rmse),
    min_rmse = min(rmse),
    max_rmse = max(rmse)
  )

rmse_summary
```


```{r comparison plot}
cv_plot <- cv_results %>%
  select(rmse_main, rmse_interactions, rmse_proposed) %>%
  pivot_longer(everything(), names_to = "model", values_to = "rmse") %>%
  mutate(model = case_when(
    model == "rmse_main" ~ "Main Effects\n(length + gestational age)",
    model == "rmse_interactions" ~ "Interactions\n(head * length * sex)",
    model == "rmse_proposed" ~ "Proposed Model\n(multiple predictors)"
  )) %>%
  mutate(model = fct_reorder(model, rmse)) %>%
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin(alpha = 0.6) +
  geom_boxplot(width = 0.2, alpha = 0.8) +
  labs(
    title = "Cross-Validated Prediction Error Comparison",
    x = "Model",
    y = "Root Mean Squared Error (RMSE)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "none",
    axis.text.x = element_text(size = 9)
  ) +
  scale_fill_brewer(palette = "Set2")

cv_plot
```


My modeling process is by using cross-validation to compare three models, the results show that the simple main effects model (length + gestational age only) has the highest RMSE (mean around 330 grams), indicating substantial underfitting and poor predictive performance. In contrast, both the interactions model (head circumference × length × sex with three-way interaction) and my proposed model show significantly better prediction accuracy with similar RMSE values (mean about 290 grams). While the interactions model captures complex relationships among physical measurements, my proposed model offers better interpretability by explicitly incorporating clinically meaningful variables like maternal smoking and BMI, making it more useful for understanding modifiable risk factors. The residual plot for my proposed model shows relatively random scatter around zero with no obvious patterns, suggesting the model adequately captures the underlying relationships and meets linear regression assumptions, though some slight heteroscedasticity may be present at extreme fitted values.